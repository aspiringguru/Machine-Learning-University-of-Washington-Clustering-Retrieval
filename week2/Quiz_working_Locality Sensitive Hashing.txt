Locality Sensitive Hashing

5 questions
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
1. 

(True/False) Like KD-trees, Locality Sensitive Hashing lets us compute exact nearest neighbors while inspecting only a fraction of the data points in the training set.

True

False
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
2. 

(True/False) Given two data points with high cosine similarity, the probability that a randomly drawn line would separate the two points is small.

True

False
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
3. 

(True/False) The true nearest neighbor of the query is guaranteed to fall into the same bin as the query.

True

False
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
4. 

(True/False) Locality Sensitive Hashing is more efficient than KD-trees in high dimensional setting.

True

False
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
5. 

Suppose you trained an LSH model and performed a lookup using the bin index of the query. You notice that the list of candidates returned are not at all similar to the query item. Which of the following changes would not produce a more relevant list of candidates?

Use multiple tables.

Increase the number of random lines/hyperplanes.

Inspect more neighboring bins to the bin containing the query.

Decrease the number of random lines/hyperplanes.
------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------
